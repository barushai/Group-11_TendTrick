# app.py ‚Äî CO5173 TikTok Hashtag Intelligence (Databricks Lakehouse)
# UI n√¢ng c·∫•p V5: Th√™m Tab 9 - AI Ph√¢n t√≠ch K√™nh & Tab 10 - Promote
# S·ª≠ d·ª•ng Python Requests ƒë·ªÉ g·ªçi Generative AI

import streamlit as st
import pandas as pd
from typing import List, Optional, Dict
import requests  # Th√™m th∆∞ vi·ªán ƒë·ªÉ g·ªçi API
import json      # Th√™m th∆∞ vi·ªán ƒë·ªÉ x·ª≠ l√Ω JSON

# ---- Plotly import guard ----
try:
    import plotly.express as px
except Exception:
    px = None

from util.db import run_sql
from util.filters import sidebar_filters

# ---- C·∫•u h√¨nh trang (Page Config) ----
st.set_page_config(
    page_title="TikTok Creator Studio - Quy·∫øt ƒë·ªãnh N·ªôi dung",
    page_icon="üí°",  # Icon m·ªõi
    layout="wide"
)
st.title("üí° TikTok Creator Studio")
st.caption("Dashboard 10 Ch·ª©c nƒÉng h·ªó tr·ª£ Ra Quy·∫øt ƒë·ªãnh S√°ng t·∫°o & Qu·∫£ng b√°")

# ---------------- Helpers ----------------
def _sql_quote(val: str) -> str:
    if val is None:
        return "NULL"
    return "'" + str(val).replace("'", "''") + "'"

def _in_list_sql(values: List[str]) -> str:
    return ",".join(_sql_quote(v) for v in values)

def _date_expr(col: str) -> str:
    return f"DATE({col})"

@st.cache_data(ttl=600)  # Gi·ªØ cache 10 ph√∫t
def run_sql_safe(sql: str) -> pd.DataFrame:
    try:
        return run_sql(sql)
    except Exception as e:
        st.warning(f"SQL error: {e}")
        return pd.DataFrame()

def dedup_cols(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return df
    return df.loc[:, ~pd.Index(df.columns).duplicated()]

def uniquify_columns(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return df
    seen: Dict[str, int] = {}
    new_cols: List[str] = []
    for c in df.columns:
        if c in seen:
            seen[c] += 1
            new_cols.append(f"{c}__{seen[c]}")
        else:
            seen[c] = 0
            new_cols.append(c)
    df.columns = new_cols
    return df

# Helper ƒë·ªÉ hi·ªÉn th·ªã b·∫£ng trong expander (∆Øu ti√™n bi·ªÉu ƒë·ªì)
def show_data_expander(df: pd.DataFrame, title: str = "Xem d·ªØ li·ªáu chi ti·∫øt (b·∫£ng)"):
    if not df.empty:
        with st.expander(title):
            st.dataframe(df, use_container_width=True)

def plot_stretch(fig):
    st.plotly_chart(fig, use_container_width=True)  # Gi·ªØ nguy√™n ƒë·ªÉ tr√°nh l·ªói version

def csv_download(df: pd.DataFrame, filename: str):
    if not df.empty:
        st.download_button("‚¨áÔ∏è T·∫£i CSV", df.to_csv(index=False).encode("utf-8"), filename, "text/csv")

def table_columns(table: str) -> List[str]:
    df = run_sql_safe(f"SHOW COLUMNS IN {table}")
    cols: List[str] = []
    if not df.empty:
        if 'col_name' in df.columns:
            cols = [str(x).strip() for x in df['col_name'].tolist() if x and str(x).strip() != '']
        else:
            cols = [c for c in df.columns]
    else:
        ddf = run_sql_safe(f"DESCRIBE TABLE {table}")
        if not ddf.empty and 'col_name' in ddf.columns:
            cols = [str(x).strip() for x in ddf['col_name'].tolist()
                    if x and not str(x).startswith('#') and str(x).lower() != 'partition']
    return [c for c in cols if c and c.lower() != 'partition']

# ------------- Load meta -------------
meta = run_sql_safe("SELECT MIN(dt) AS min_d, MAX(dt) AS max_d FROM silver.silver_trend")
min_d = meta.iloc[0]["min_d"] if not meta.empty else None
max_d = meta.iloc[0]["max_d"] if not meta.empty else None

countries_df = run_sql_safe("""
    SELECT DISTINCT country_code
    FROM silver.silver_trend
    WHERE country_code IS NOT NULL
    ORDER BY country_code
""")
countries = [str(x) for x in countries_df["country_code"].tolist()] if not countries_df.empty else []

industries_df = run_sql_safe("""
    SELECT DISTINCT industry
    FROM silver.silver_trend
    WHERE industry IS NOT NULL
    ORDER BY industry
""")
industries = [str(x) for x in industries_df["industry"].tolist()] if not industries_df.empty else []

# Sidebar filters
START_DATE, END_DATE, COUNTRIES, INDUSTRIES, KEYWORD, TOPN = sidebar_filters(
    min_d if pd.notna(min_d) else None,
    max_d if pd.notna(max_d) else None,
    countries,
    industries,
)

# ------------- WHERE-builder -------------
def build_where(
    dt_col: Optional[str] = "dt",
    country_col: Optional[str] = "country_code",
    industry_col: Optional[str] = "industry",
    hashtag_expr: Optional[str] = "COALESCE(hashtag_raw, hashtag)",
) -> str:
    """
    X√¢y WHERE clause theo filter global. 
    L∆∞u √Ω:
      - N·∫øu hashtag_expr=None th√¨ s·∫Ω b·ªè qua filter KEYWORD (d√πng cho b·∫£ng kh√¥ng c√≥ hashtag).
    """
    clauses: List[str] = []
    if dt_col and START_DATE and END_DATE:
        clauses.append(f"{_date_expr(dt_col)} BETWEEN DATE('{START_DATE}') AND DATE('{END_DATE}')")
    if country_col and COUNTRIES and COUNTRIES != ["ALL"]:
        items = [c for c in COUNTRIES if c != "ALL"]
        if items:
            clauses.append(f"{country_col} IN ({_in_list_sql(items)})")
    if industry_col and INDUSTRIES and INDUSTRIES != ["ALL"]:
        items = [i for i in INDUSTRIES if i != "ALL"]
        if items:
            clauses.append(f"{industry_col} IN ({_in_list_sql(items)})")
    if KEYWORD and hashtag_expr:
        kw = str(KEYWORD).lower().replace("'", "''")
        clauses.append(f"LOWER({hashtag_expr}) LIKE '%{kw}%'")
    return (" WHERE " + " AND ".join(clauses)) if clauses else ""

# ------------- Action buttons (Simplified) -------------
if st.sidebar.button("üîÑ Refresh Cache (10m)"):
    st.cache_data.clear()
    st.sidebar.success("Cache cleared.")

# --------- KPI header ---------
st.divider()
colA, colB, colC, colD = st.columns(4)
sql_kpi = f"""
SELECT
  COUNT(DISTINCT hashtag) AS uniq_hashtags,
  COUNT(DISTINCT CASE WHEN {_date_expr('dt')} = (SELECT MAX(DATE(dt)) FROM silver.silver_trend) THEN hashtag END) AS today_tags,
  COUNT(DISTINCT country_code) AS uniq_countries,
  COUNT(DISTINCT industry) AS uniq_industries
FROM silver.silver_trend
{build_where(dt_col='dt', hashtag_expr='COALESCE(hashtag_raw, hashtag)')}
"""
kpi = run_sql_safe(sql_kpi)
a = int(kpi.iloc[0]["uniq_hashtags"] or 0) if not kpi.empty else 0
b = int(kpi.iloc[0]["today_tags"] or 0)    if not kpi.empty else 0
c = int(kpi.iloc[0]["uniq_countries"] or 0)if not kpi.empty else 0
d = int(kpi.iloc[0]["uniq_industries"] or 0)if not kpi.empty else 0
colA.metric("Hashtags trong ph·∫°m vi", f"{a:,}")
colB.metric("Hashtags h√¥m m·ªõi nh·∫•t", f"{b:,}")
colC.metric("Qu·ªëc gia", f"{c:,}")
colD.metric("Ng√†nh", f"{d:,}")
st.caption("C√°c KPI ph·∫£n √°nh b·ªô l·ªçc hi·ªán t·∫°i trong sidebar.")
st.divider()

# ------------- T·∫£i D·ªØ li·ªáu 1 l·∫ßn (T·ªëi ∆∞u) -------------

# L·∫•y d·ªØ li·ªáu Momentum (d√πng cho Tab 2)
sql_m = f"""
  WITH b AS (
    SELECT DISTINCT DATE(dt) AS dt, hashtag, country_code, industry, hashtag_raw
    FROM silver.silver_trend
  ),
  m AS (
    SELECT dt, hashtag, rank, prev_rank, rank_velocity, view_delta, video_delta
    FROM gold.trend_momentum
  ),
  j AS (
    SELECT m.*, b.country_code, b.industry, b.hashtag_raw
    FROM m LEFT JOIN b ON DATE(m.dt)=b.dt AND m.hashtag=b.hashtag
  )
  SELECT * FROM j
  {build_where(dt_col='j.dt', country_col='j.country_code', industry_col='j.industry',
              hashtag_expr='COALESCE(j.hashtag_raw, j.hashtag)')}
"""
mom = run_sql_safe(sql_m)
if mom.empty:
    sql_fb = f"""
      WITH s AS (
        SELECT DATE(dt) dt, hashtag, rank, view_count, video_count, country_code, industry, hashtag_raw
        FROM silver.silver_trend
      ),
      best AS (
        SELECT * FROM (
          SELECT s.*, ROW_NUMBER() OVER (PARTITION BY dt, hashtag ORDER BY COALESCE(rank,999), view_count DESC) rn
          FROM s
        ) x WHERE rn=1
      ),
      x AS (
        SELECT
          dt, hashtag, rank,
          LAG(rank) OVER (PARTITION BY hashtag ORDER BY dt) AS prev_rank,
          (LAG(rank) OVER (PARTITION BY hashtag ORDER BY dt) - rank) AS rank_velocity,
          (view_count - LAG(view_count) OVER (PARTITION BY hashtag ORDER BY dt)) AS view_delta,
          (video_count - LAG(video_count) OVER (PARTITION BY hashtag ORDER BY dt)) AS video_delta,
          country_code, industry, hashtag_raw
        FROM best
      )
      SELECT * FROM x
      {build_where(dt_col='dt', country_col='country_code', industry_col='industry',
                   hashtag_expr='COALESCE(hashtag_raw, hashtag)')}
    """
    mom = run_sql_safe(sql_fb)

mom = uniquify_columns(dedup_cols(mom))
mom["view_delta"] = pd.to_numeric(mom.get("view_delta"), errors="coerce").fillna(0)
mom["rank_velocity"] = pd.to_numeric(mom.get("rank_velocity"), errors="coerce").fillna(0)
latest_mom_dt = mom['dt'].max() if not mom.empty else "N/A"
mom_latest = mom[mom['dt'] == latest_mom_dt] if not mom.empty else pd.DataFrame()

# L·∫•y d·ªØ li·ªáu Retention (d√πng cho Tab 3, 4)
sql_ret = f"""
  WITH base AS (
    SELECT DISTINCT DATE(dt) AS dt, hashtag, url, country_code, industry, hashtag_raw
    FROM silver.silver_trend
  ),
  j AS (
    SELECT r.hashtag, r.start_dt, r.end_dt, r.streak_days,
           b.url, b.country_code, b.industry, b.hashtag_raw
    FROM gold.trend_retention r
    LEFT JOIN base b ON r.hashtag=b.hashtag AND r.end_dt=b.dt
  )
  SELECT * FROM j
  {build_where(dt_col='j.end_dt', country_col='j.country_code', industry_col='j.industry',
               hashtag_expr='COALESCE(j.hashtag_raw, j.hashtag)')}
"""
df_ret = run_sql_safe(sql_ret)
if df_ret.empty:
    sql_ret_fb = f"""
      WITH s AS (
        SELECT DISTINCT DATE(dt) dt, hashtag FROM silver.silver_trend
      ),
      g AS (
        SELECT hashtag, dt,
          DATEDIFF(dt, DATE'1970-01-01') - ROW_NUMBER() OVER (PARTITION BY hashtag ORDER BY dt) grp
        FROM s
      ),
      streaks AS (
        SELECT hashtag, MIN(dt) start_dt, MAX(dt) end_dt, COUNT(*) streak_days
        FROM g GROUP BY hashtag, grp
      ),
      dim AS (
        SELECT DISTINCT DATE(dt) dt, hashtag, url, country_code, industry, hashtag_raw
        FROM silver.silver_trend
      )
      SELECT r.hashtag, r.start_dt, r.end_dt, r.streak_days,
             d.url, d.country_code, d.industry, d.hashtag_raw
      FROM streaks r
      LEFT JOIN dim d ON r.hashtag=d.hashtag AND r.end_dt=d.dt
      {build_where(dt_col='r.end_dt', country_col='d.country_code', industry_col='d.industry',
                   hashtag_expr='COALESCE(d.hashtag_raw, r.hashtag)')}
    """
    df_ret = run_sql_safe(sql_ret_fb)
df_ret = uniquify_columns(dedup_cols(df_ret))

# L·∫•y d·ªØ li·ªáu New Entries (d√πng cho Tab 3)
sql_new = f"""
WITH base AS (SELECT DISTINCT DATE(dt) dt, hashtag FROM silver.silver_trend),
     firsts AS (SELECT hashtag, MIN(dt) dt FROM base GROUP BY hashtag)
SELECT dt, COUNT(*) AS new_count
FROM firsts
{build_where(dt_col='dt', country_col=None, industry_col=None, hashtag_expr='hashtag')}
GROUP BY dt
ORDER BY dt
"""
df_new = run_sql_safe(sql_new)

# ------------- Tabs (C·∫•u tr√∫c 10 Ch·ª©c nƒÉng S√°ng t·∫°o) -------------
tabs = st.tabs([
    "üéØ 1. T√¨m Ng√°ch (Niche Finder)",
    "üî• 2. ƒê·ªông l∆∞·ª£ng Trend (Momentum)",
    "‚ö° 3. Chi·∫øn l∆∞·ª£c Trend Nhanh",
    "üå≥ 4. Chi·∫øn l∆∞·ª£c B·ªÅn v·ªØng",
    "üìä 5. Ph√¢n t√≠ch B√£o h√≤a Ng√†nh",
    "üåç 6. Ph√¢n t√≠ch Th·ªã tr∆∞·ªùng QG",
    "üèÜ 7. Top 100 ƒê√£ Ki·ªÉm ch·ª©ng",
    "üìÖ 8. L·∫≠p k·∫ø ho·∫°ch Tu·∫ßn",
    "ü§ñ 9. AI Ph√¢n t√≠ch K√™nh",   # <-- TAB 9
    "üì£ 10. Ph√¢n t√≠ch Promote"   # <-- TAB 10 m·ªõi
])

# ===== üéØ 1. T√¨m Ng√°ch (Niche Finder) =====
with tabs[0]:
    st.subheader("üéØ 1. Ph√°t hi·ªán C∆° h·ªôi (Niche Finder)")
    st.markdown("Ch·ª©c nƒÉng: T√¨m hashtag c√≥ **l∆∞·ª£t xem (Demand) cao** nh∆∞ng **s·ªë video (Competition) th·∫•p**."
                " H√£y t√¨m c√°c ƒëi·ªÉm ·ªü **g√≥c tr√™n b√™n tr√°i**.")

    sql_opp = f"""
        WITH mx AS (SELECT MAX(dt) AS mx FROM silver.silver_trend)
        SELECT
          t.hashtag, t.view_count, t.video_count,
          t.industry, t.country_code, t.rank
        FROM gold.trend_latest_top100 t
        JOIN mx ON t.dt = mx.mx
        {build_where(dt_col='t.dt', country_col='t.country_code', industry_col='t.industry',
                     hashtag_expr='COALESCE(t.hashtag_raw, t.hashtag)')}
    """
    df_opp = run_sql_safe(sql_opp)
    
    # Fallback n·∫øu gold r·ªóng
    if df_opp.empty:
        sql_opp_fb = f"""
            WITH mx AS (SELECT MAX(DATE(dt)) AS mx FROM silver.silver_trend),
            s AS (
                SELECT *, ROW_NUMBER() OVER (PARTITION BY hashtag ORDER BY view_count DESC) rn
                FROM silver.silver_trend
                WHERE DATE(dt) = (SELECT mx FROM mx)
            )
            SELECT hashtag, view_count, video_count, industry, country_code, rank
            FROM s WHERE rn = 1
            {build_where(dt_col=None, country_col='country_code', industry_col='industry',
                         hashtag_expr='COALESCE(hashtag_raw, hashtag)')}
        """
        df_opp = run_sql_safe(sql_opp_fb)

    if not df_opp.empty and px is not None and "view_count" in df_opp.columns and "video_count" in df_opp.columns:
        df_opp_plot = df_opp.dropna(subset=["view_count", "video_count"])
        df_opp_plot = df_opp_plot[df_opp_plot['view_count'] > 0]
        df_opp_plot = df_opp_plot[df_opp_plot['video_count'] > 0]
        
        if not df_opp_plot.empty:
            fig_opp = px.scatter(
                df_opp_plot,
                x="video_count",
                y="view_count",
                color="industry",
                size="view_count",
                hover_data=["hashtag", "country_code", "rank"],
                title="Bi·ªÉu ƒë·ªì C∆° h·ªôi: L∆∞·ª£t xem (Y) vs. C·∫°nh tranh (X)",
                labels={"video_count": "S·ªë l∆∞·ª£ng video (C·∫°nh tranh ‚¨ÜÔ∏è)", "view_count": "S·ªë l∆∞·ª£t xem (Nhu c·∫ßu ‚¨ÜÔ∏è)"}
            )
            fig_opp.update_xaxes(type="log") 
            fig_opp.update_yaxes(type="log") 
            plot_stretch(fig_opp)
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu (sau khi l·ªçc) cho bi·ªÉu ƒë·ªì c∆° h·ªôi.")
            
    elif px is None:
        st.warning("C√†i ƒë·∫∑t Plotly ƒë·ªÉ xem bi·ªÉu ƒë·ªì.")
    else:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì c∆° h·ªôi.")
    
    show_data_expander(df_opp, "Xem d·ªØ li·ªáu c∆° h·ªôi")
    csv_download(df_opp, "opportunity_latest.csv")

# ===== üî• 2. ƒê·ªông l∆∞·ª£ng Trend (Momentum) =====
with tabs[1]:
    st.subheader("üî• 2. Ph√¢n t√≠ch ƒê·ªông l∆∞·ª£ng Trend (Momentum)")
    st.markdown("Ch·ª©c nƒÉng: Xem nhanh c√°c hashtag 'N√≥ng', 'Ng√¥i sao' v√† 'Ngu·ªôi' trong ng√†y."
                f" (D·ªØ li·ªáu ng√†y: **{latest_mom_dt}**)")

    if not mom_latest.empty and px is not None:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("#### üî• Trend N√≥ng (Views)")
            df_rising = mom_latest.sort_values("view_delta", ascending=False).head(15)
            if not df_rising.empty:
                fig_rising = px.bar(
                    df_rising, x="view_delta", y="hashtag", orientation="h",
                    title="Top 15 TƒÉng View",
                    labels={"view_delta": "Thay ƒë·ªïi L∆∞·ª£t xem (DoD)", "hashtag": "Hashtag"},
                    hover_data=["industry", "rank", "rank_velocity"]
                )
                fig_rising.update_layout(yaxis={'categoryorder':'total ascending'})
                plot_stretch(fig_rising)
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu tƒÉng tr∆∞·ªüng.")

        with col2:
            st.markdown("#### ‚ú® Ng√¥i sao m·ªõi (Rank)")
            df_rank_rising = mom_latest.sort_values("rank_velocity", ascending=False).head(15)
            if not df_rank_rising.empty:
                fig_rank_rising = px.bar(
                    df_rank_rising, x="rank_velocity", y="hashtag", orientation="h",
                    title="Top 15 TƒÉng H·∫°ng nhanh nh·∫•t",
                    labels={"rank_velocity": "Thay ƒë·ªïi H·∫°ng (DoD)", "hashtag": "Hashtag"},
                    hover_data=["industry", "rank", "view_delta"]
                )
                fig_rank_rising.update_layout(yaxis={'categoryorder':'total ascending'})
                plot_stretch(fig_rank_rising)
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu tƒÉng tr∆∞·ªüng h·∫°ng.")
        
        with col3:
            st.markdown("#### ‚ùÑÔ∏è Trend Ngu·ªôi (Fading)")
            df_fading = mom_latest.sort_values("view_delta", ascending=True).head(15)
            if not df_fading.empty:
                fig_fading = px.bar(
                    df_fading, x="view_delta", y="hashtag", orientation="h",
                    title="Top 15 Gi·∫£m View",
                    labels={"view_delta": "Thay ƒë·ªïi L∆∞·ª£t xem (DoD)", "hashtag": "Hashtag"},
                    hover_data=["industry", "rank", "rank_velocity"]
                )
                fig_fading.update_layout(yaxis={'categoryorder':'total descending'})
                plot_stretch(fig_fading)
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu suy gi·∫£m.")
    else:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu Momentum cho ng√†y m·ªõi nh·∫•t.")
        
    show_data_expander(mom, "Xem to√†n b·ªô d·ªØ li·ªáu Momentum")

# ===== ‚ö° 3. Chi·∫øn l∆∞·ª£c Trend Nhanh =====
with tabs[2]:
    st.subheader("‚ö° 3. Chi·∫øn l∆∞·ª£c Trend Nhanh (Short-term)")
    st.markdown("Ch·ª©c nƒÉng: Hi·ªÉu t·ªëc ƒë·ªô c·ªßa trend. H·∫ßu h·∫øt trend 's·ªëng' bao l√¢u v√† m·ªói ng√†y c√≥ bao nhi√™u trend m·ªõi?")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### V√≤ng ƒë·ªùi Xu h∆∞·ªõng (Trend Lifespan)")
        if not df_ret.empty and px is not None:
            df_life = df_ret.copy()
            fig_life = px.histogram(
                df_life, x="streak_days",
                title="Ph√¢n b·ªï V√≤ng ƒë·ªùi Xu h∆∞·ªõng",
                labels={"streak_days": "S·ªë ng√†y li√™n t·ª•c (Streak)", "count": "S·ªë l∆∞·ª£ng chu·ªói (Count)"},
                nbins=max(20, int(df_life["streak_days"].max())) 
            )
            plot_stretch(fig_life)
        elif px is None:
            st.warning("C√†i ƒë·∫∑t Plotly.")
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu V√≤ng ƒë·ªùi xu h∆∞·ªõng.")
            
    with col2:
        st.markdown("#### L∆∞·ª£ng Hashtag M·ªõi H√†ng Ng√†y")
        if not df_new.empty and px is not None:
            fig_new = px.bar(df_new, x="dt", y="new_count", title="S·ªë hashtag m·ªõi theo ng√†y")
            plot_stretch(fig_new)
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu Hashtag m·ªõi.")

    show_data_expander(df_new.merge(df_ret, how='cross'), "Xem d·ªØ li·ªáu (K·∫øt h·ª£p)")

# ===== üå≥ 4. Chi·∫øn l∆∞·ª£c B·ªÅn v·ªØng =====
with tabs[3]:
    st.subheader("üå≥ 4. Chi·∫øn l∆∞·ª£c B·ªÅn v·ªØng (Long-term)")
    st.markdown("Ch·ª©c nƒÉng: T√¨m c√°c ch·ªß ƒë·ªÅ/hashtag 'evergreen' ƒë·ªÉ x√¢y d·ª±ng n·ªôi dung k√™nh d√†i h·∫°n.")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### Top 20 Hashtag 's·ªëng dai' nh·∫•t")
        if not df_ret.empty and px is not None and "streak_days" in df_ret.columns:
            top_streak = df_ret.sort_values("streak_days", ascending=False).head(20)
            fig_streak = px.bar(top_streak, x="streak_days", y="hashtag", orientation="h", title="Top 20 chu·ªói d√†i nh·∫•t")
            fig_streak.update_yaxes(autorange="reversed")
            plot_stretch(fig_streak)
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu Retention.")
    
    with col2:
        st.markdown("#### Top 10 Ng√†nh B·ªÅn v·ªØng nh·∫•t")
        if not df_ret.empty and px is not None:
            df_ret_agg = df_ret.groupby('industry')['streak_days'].mean().reset_index().sort_values('streak_days', ascending=False).head(10)
            if not df_ret_agg.empty:
                fig_ret_agg = px.bar(
                    df_ret_agg, x="streak_days", y="industry", orientation="h",
                    title="Top 10 Ng√†nh B·ªÅn v·ªØng (TB s·ªë ng√†y trend)",
                    labels={"streak_days": "S·ªë ng√†y trend trung b√¨nh", "industry": "Ng√†nh"}
                )
                fig_ret_agg.update_yaxes(autorange="reversed")
                plot_stretch(fig_ret_agg)
            else:
                st.info("Kh√¥ng th·ªÉ t√≠nh TB ng√†nh.")
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu Retention.")
            
    show_data_expander(df_ret, "Xem d·ªØ li·ªáu Retention chi ti·∫øt")
    csv_download(df_ret, "retention.csv")

# ===== üìä 5. Ph√¢n t√≠ch B√£o h√≤a Ng√†nh =====
with tabs[4]:
    st.subheader("üìä 5. Ph√¢n t√≠ch B√£o h√≤a & Hi·ªáu qu·∫£ Ng√†nh")
    st.markdown("Ch·ª©c nƒÉng: Ng√†nh n√†o ƒëang c√≥ nhi·ªÅu 'Th·ªã ph·∫ßn' (Views) v√† ng√†nh n√†o 'Hi·ªáu qu·∫£' (d·ªÖ c√≥ view) nh·∫•t?")
    
    mx = run_sql_safe("SELECT MAX(DATE(dt)) AS mx FROM silver.silver_trend")
    latest = mx.iloc[0]["mx"] if not mx.empty else None
    
    if latest:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"#### C∆° c·∫•u Th·ªã ph·∫ßn (Views) - Ng√†y {latest}")
            extra = ""
            if COUNTRIES and COUNTRIES != ["ALL"]:
                extra += f" AND country_code IN ({_in_list_sql([c for c in COUNTRIES if c!='ALL'])})"
            if KEYWORD:
                kw = str(KEYWORD).lower().replace("'", "''")
                extra += f" AND LOWER(COALESCE(hashtag_raw, hashtag)) LIKE '%{kw}%'"
            sql_ind = f"""
            SELECT industry, SUM(view_count) AS total_views
            FROM silver.silver_trend
            WHERE DATE(dt)=DATE('{latest}') AND industry IS NOT NULL
            {extra}
            GROUP BY industry ORDER BY total_views DESC LIMIT 12
            """
            df_ind = run_sql_safe(sql_ind)
            if not df_ind.empty and px is not None:
                fig3 = px.pie(df_ind, names="industry", values="total_views", title=f"C∆° c·∫•u view theo ng√†nh")
                plot_stretch(fig3)
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu c∆° c·∫•u ng√†nh.")

        with col2:
            st.markdown(f"#### Hi·ªáu qu·∫£ Ng√†nh (Views / Video) - Ng√†y {latest}")
            sql_eff = f"""
                SELECT 
                    industry, 
                    SUM(view_count) AS total_views, 
                    SUM(video_count) AS total_videos,
                    SUM(view_count) / NULLIF(SUM(video_count), 0) AS view_per_video
                FROM silver.silver_trend
                WHERE DATE(dt)=DATE('{latest}') 
                  AND industry IS NOT NULL 
                  AND video_count > 0
                {extra}  
                GROUP BY industry 
                ORDER BY view_per_video DESC
                LIMIT 15
            """
            df_eff = run_sql_safe(sql_eff)
            if not df_eff.empty and px is not None:
                fig_eff = px.bar(
                    df_eff, x="view_per_video", y="industry", orientation="h",
                    title="Top 15 Ng√†nh Hi·ªáu qu·∫£ nh·∫•t",
                    labels={"view_per_video": "L∆∞·ª£t View / 1 Video", "industry": "Ng√†nh"},
                    hover_data=["total_views", "total_videos"]
                )
                fig_eff.update_yaxes(autorange="reversed")
                plot_stretch(fig_eff)
            else:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu hi·ªáu qu·∫£ ng√†nh.")
        
        merged = pd.DataFrame()
        if 'df_ind' in locals() and 'df_eff' in locals():
            try:
                merged = df_ind.merge(df_eff, on='industry', how='outer')
            except Exception:
                merged = pd.DataFrame()
        show_data_expander(merged, "Xem d·ªØ li·ªáu Ng√†nh chi ti·∫øt")

    else:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu cho ng√†y m·ªõi nh·∫•t.")

# ===== üåç 6. Ph√¢n t√≠ch Th·ªã tr∆∞·ªùng QG =====
with tabs[5]:
    st.subheader("üåç 6. Ph√¢n t√≠ch Th·ªã tr∆∞·ªùng Qu·ªëc gia")
    st.markdown("Ch·ª©c nƒÉng: Xem t·ªïng quan th·ªã tr∆∞·ªùng theo qu·ªëc gia. Th·ªã tr∆∞·ªùng n√†o ƒëang ph√°t tri·ªÉn nhanh nh·∫•t?")

    gold_country_cols = table_columns("gold.trend_country_summary")
    df_ct = pd.DataFrame()
    if any(c in gold_country_cols for c in ["total_views", "views", "view_sum"]):
        col_name = "total_views" if "total_views" in gold_country_cols else ("views" if "views" in gold_country_cols else "view_sum")
        sql_country = f"""
            SELECT dt, country_code, {col_name} AS total_views
            FROM gold.trend_country_summary
            {build_where(dt_col='dt', country_col='country_code', industry_col=None, hashtag_expr=None)}
            ORDER BY dt, country_code
        """
        df_ct = run_sql_safe(sql_country)

    if df_ct.empty:
        sql_country_fb = f"""
        SELECT DATE(dt) dt, country_code, SUM(view_count) AS total_views
        FROM silver.silver_trend
        {build_where(dt_col='dt', country_col='country_code', industry_col=None,
                     hashtag_expr='COALESCE(hashtag_raw, hashtag)')}
        GROUP BY 1,2 ORDER BY 1,2
        """
        df_ct = run_sql_safe(sql_country_fb)

    if not df_ct.empty and px is not None:
        fig_ct = px.area(df_ct, x="dt", y="total_views", color="country_code", title="T·ªïng view theo qu·ªëc gia (stacked)")
        plot_stretch(fig_ct)
    show_data_expander(df_ct, "Xem d·ªØ li·ªáu View theo Qu·ªëc gia")
    csv_download(df_ct, "views_by_country.csv")

# ===== üèÜ 7. Top 100 ƒê√£ Ki·ªÉm ch·ª©ng =====
with tabs[6]:
    st.subheader("üèÜ 7. Top 100 ƒê√£ Ki·ªÉm ch·ª©ng (Proven Winners)")
    st.markdown("Ch·ª©c nƒÉng: Danh s√°ch 100 hashtag h√†ng ƒë·∫ßu ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh hi·ªáu qu·∫£."
                " D√πng cho c√°c chi·∫øn d·ªãch c·∫ßn s·ª± an to√†n, ƒë√£ ki·ªÉm ch·ª©ng (proven winners).")
    
    df_top100 = run_sql_safe(f"""
        WITH mx AS (SELECT MAX(dt) AS mx FROM silver.silver_trend)
        SELECT
          t.dt, t.hashtag, t.rank, t.view_count, t.video_count,
          t.country_code, t.industry, t.category,
          t.hashtag_raw, t.url
        FROM gold.trend_latest_top100 t
        JOIN mx ON t.dt = mx.mx
        {build_where(dt_col='t.dt', country_col='t.country_code', industry_col='t.industry',
                     hashtag_expr='COALESCE(t.hashtag_raw, t.hashtag)')}
        ORDER BY COALESCE(t.rank, 999) ASC
        LIMIT 100
    """)
    df_top100 = uniquify_columns(dedup_cols(df_top100))
    
    if not df_top100.empty and px is not None:
        topn_val = min(20, len(df_top100))
        fig_top100_bar = px.bar(
            df_top100.head(topn_val),
            x="view_count", y="hashtag",
            color="industry",
            orientation="h",
            title=f"Top {topn_val} theo view (latest day)",
            hover_data=["rank", "video_count", "country_code"]
        )
        fig_top100_bar.update_yaxes(autorange="reversed")
        plot_stretch(fig_top100_bar)
    
    show_data_expander(df_top100, "Xem d·ªØ li·ªáu Top 100 M·ªõi nh·∫•t")
    csv_download(df_top100, "latest_top100.csv")

# ===== üìÖ 8. L·∫≠p k·∫ø ho·∫°ch Tu·∫ßn =====
with tabs[7]:
    st.subheader("üìÖ 8. L·∫≠p k·∫ø ho·∫°ch theo Tu·∫ßn (Weekly Planner)")
    st.markdown("Ch·ª©c nƒÉng: Xem xu h∆∞·ªõng th·ª© h·∫°ng trung b√¨nh c·ªßa hashtag theo tu·∫ßn. "
                "D√πng ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch n·ªôi dung h√†ng tu·∫ßn.")
    
    # SQL Builder ri√™ng cho Weekly (v√¨ dt_col l√† 'week')
    where_parts: List[str] = []
    if START_DATE and END_DATE:
        where_parts.append(
            "DATE(w.week) BETWEEN DATE(DATE_TRUNC('week', DATE('{s}'))) AND DATE(DATE_TRUNC('week', DATE('{e}')))"
            .format(s=START_DATE, e=END_DATE)
        )
    if COUNTRIES and COUNTRIES != ["ALL"]:
        where_parts.append(f"b.country_code IN ({_in_list_sql([c for c in COUNTRIES if c!='ALL'])})")
    if INDUSTRIES and INDUSTRIES != ["ALL"]:
        where_parts.append(f"b.industry IN ({_in_list_sql([i for i in INDUSTRIES if i!='ALL'])})")
    if KEYWORD:
        kw = str(KEYWORD).lower().replace("'", "''")
        where_parts.append("LOWER(COALESCE(b.hashtag_raw, w.hashtag)) LIKE '%" + kw + "%'")
    weekly_where = (" WHERE " + " AND ".join(where_parts)) if where_parts else ""

    sql_week = f"""
      WITH b AS (
        SELECT DISTINCT DATE(dt) dt, hashtag, country_code, industry, hashtag_raw
        FROM silver.silver_trend
      )
      SELECT w.week, w.hashtag, w.best_rank, w.avg_rank, w.new_days_count, w.max_views,
             b.country_code, b.industry, b.hashtag_raw
      FROM gold.trend_weekly_summary w
      LEFT JOIN b ON w.hashtag = b.hashtag
      {weekly_where}
      ORDER BY w.week DESC, COALESCE(w.best_rank, 999) ASC
    """
    dfw = run_sql_safe(sql_week)
    if dfw.empty:
        sql_fb = f"""
          WITH base AS (
            SELECT DATE(dt) dt, hashtag, COALESCE(rank,999) rank, view_count
            FROM silver.silver_trend
          ),
          best AS (
            SELECT * FROM (
              SELECT base.*, ROW_NUMBER() OVER (PARTITION BY dt, hashtag ORDER BY rank, view_count DESC) rn
              FROM base
            ) x WHERE rn=1
          ),
          w AS (
            SELECT DATE_TRUNC('week', dt) AS week, hashtag,
                   MIN(rank) AS best_rank, AVG(rank) AS avg_rank,
                   COUNT(*) AS new_days_count, MAX(view_count) AS max_views
            FROM best GROUP BY 1,2
          ),
          b AS (
            SELECT DISTINCT DATE(dt) dt, hashtag, country_code, industry, hashtag_raw
            FROM silver.silver_trend
          )
          SELECT w.week, w.hashtag, w.best_rank, w.avg_rank, w.new_days_count, w.max_views,
                 b.country_code, b.industry, b.hashtag_raw
          FROM w LEFT JOIN b ON w.hashtag=b.hashtag
          {weekly_where}
          ORDER BY w.week DESC, COALESCE(w.best_rank,999) ASC
        """
        dfw = run_sql_safe(sql_fb)

    dfw = uniquify_columns(dedup_cols(dfw))
    
    if not dfw.empty and px is not None and "hashtag" in dfw.columns and "avg_rank" in dfw.columns:
        top_tags = dfw.sort_values(["best_rank"]).dropna(subset=["best_rank"]).head(5)["hashtag"].unique().tolist()
        sel = st.multiselect(
            "Ch·ªçn hashtag ƒë·ªÉ xem xu h∆∞·ªõng th·ª© h·∫°ng (t·ªëi ƒëa 10)",
            options=sorted(dfw["hashtag"].unique()),
            default=top_tags[:5],
            max_selections=10
        )
        if sel:
            plot_df = dfw[dfw["hashtag"].isin(sel)].copy()
            fig = px.line(plot_df, x="week", y="avg_rank", color="hashtag", title="Xu h∆∞·ªõng th·ª© h·∫°ng TB theo tu·∫ßn")
            fig.update_yaxes(autorange="reversed") # Rank th·∫•p (1) t·ªët h∆°n
            plot_stretch(fig)
            
    show_data_expander(dfw, "Xem d·ªØ li·ªáu Weekly Summary chi ti·∫øt")
    csv_download(dfw, "weekly_summary.csv")

# ===== ü§ñ 9. AI Ph√¢n t√≠ch K√™nh =====
with tabs[8]:  # Index 8 cho tab th·ª© 9
    import datetime as _dt

    st.subheader("ü§ñ 9. AI Ph√¢n t√≠ch K√™nh & G·ª£i √Ω K·ªãch b·∫£n (No URL, No Mock)")
    st.markdown(
        "ƒêi·ªÅn **Prompt Builder** (m·ª•c ti√™u/ƒë·ªëi t∆∞·ª£ng/KPI/gi·ªçng), h·ªá th·ªëng s·∫Ω **t·ª± ƒë·ªông ch·ªçn hashtag** "
        "t·ª´ d·ªØ li·ªáu (Hot/Evergreen/Opportunity/Proven/Weekly) ƒë·ªÉ t·∫°o **√Ω t∆∞·ªüng** + **k·ªãch b·∫£n**."
    )

    # ---------------- Prompt helper: h∆∞·ªõng d·∫´n c·∫•u tr√∫c ----------------
    with st.expander("üß© H∆∞·ªõng d·∫´n c·∫•u tr√∫c Prompt g·ª£i √Ω (copy/s·ª≠a tr·ª±c ti·∫øp)"):
        st.markdown("""
**[M·ª•c ti√™u]**: TƒÉng view/engagement/CTR/ƒë∆°n h√†ng cho ..., trong ... ng√†y  
**[ƒê·ªëi t∆∞·ª£ng]**: Nam/N·ªØ, 18‚Äì24, ·ªü ..., quan t√¢m ...  
**[S·∫£n ph·∫©m/D·ªãch v·ª•]**: T√™n, l·ª£i √≠ch ch√≠nh, USP  
**[T√¥ng gi·ªçng]**: Vui v·∫ª/ƒëanh ƒë√°/chuy√™n gia/·∫•m √°p  
**[ƒê·ªãnh d·∫°ng]**: TikTok 30‚Äì45s, Hook ‚â§3s, 3 c·∫£nh ch√≠nh, cu·ªëi c√≥ CTA  
**[KPI]**: View ‚â•..., ER ‚â•..., CTR ‚â•...  
**[R√†ng bu·ªôc]**: Kh√¥ng d√πng nh·∫°c b·∫£n quy·ªÅn, kh√¥ng n√≥i gi√°, tr√°nh ƒë·ªÅ c·∫≠p ...  
**[ƒê·∫ßu ra mong mu·ªën]**:  
- 3‚Äì5 √Ω t∆∞·ªüng (ghi r√µ Hook, Visual, Voiceover, CTA)  
- 1 k·ªãch b·∫£n chi ti·∫øt 30‚Äì45s (shot-by-shot)  
- Hashtag ƒë·ªÅ xu·∫•t (k·∫øt h·ª£p niche + trend)  
- L·ªãch ƒëƒÉng 1 tu·∫ßn (gi·ªù v√†ng g·ª£i √Ω)
        """)

    # ---------------- 1) Output options ----------------
    col_lang, col_num = st.columns([1, 1])
    with col_lang:
        out_lang = st.selectbox("Ng√¥n ng·ªØ ƒë·∫ßu ra", ["Ti·∫øng Vi·ªát", "English"], index=0)
    with col_num:
        idea_count = st.number_input("S·ªë √Ω t∆∞·ªüng", min_value=1, max_value=10, value=3, step=1)

    # ---------------- 2) Prompt Builder ----------------
    st.markdown("### üõ†Ô∏è Prompt Builder")
    col_a, col_b = st.columns(2)
    with col_a:
        pb_goal = st.text_area("M·ª•c ti√™u chi·∫øn d·ªãch", height=80,
                               placeholder="VD: TƒÉng view 30% trong 14 ng√†y cho niche 'Food & Travel'‚Ä¶")
        pb_audience = st.text_area("ƒê·ªëi t∆∞·ª£ng m·ª•c ti√™u", height=80,
                                   placeholder="VD: N·ªØ 18‚Äì24, HN/HCM, th√≠ch ƒÉn u·ªëng & du l·ªãch budget‚Ä¶")
        pb_product = st.text_area("S·∫£n ph·∫©m/D·ªãch v·ª• (USP/L·ª£i √≠ch)", height=80,
                                  placeholder="VD: Tour ·∫©m th·ª±c ƒë√™m S√†i G√≤n, gi√° t·ªët, l·ªãch tr√¨nh linh ho·∫°t‚Ä¶")
    with col_b:
        pb_tone = st.text_input("T√¥ng gi·ªçng", value="Vui v·∫ª, gi√†u nƒÉng l∆∞·ª£ng, t·ª± nhi√™n")
        pb_kpi = st.text_input("KPI k·ª≥ v·ªçng", value="View ‚â• 50k/video, ER ‚â• 6%")
        pb_constraints = st.text_area("R√†ng bu·ªôc", height=80,
                                      placeholder="Kh√¥ng d√πng nh·∫°c b·∫£n quy·ªÅn; tr√°nh n√≥i gi√°; ph√π h·ª£p brand safe‚Ä¶")

    freeform_prompt = st.text_area(
        "Prompt b·ªï sung (t·ª± do, s·∫Ω g·ªôp c√πng Builder ·ªü tr√™n)",
        height=100,
        placeholder="Th√™m h∆∞·ªõng d·∫´n ri√™ng c·ªßa b·∫°n‚Ä¶"
    )

    # ---------------- Helpers ----------------
    def _dedup_ci_keep_order(seq):
        out, seen = [], set()
        for s in (seq or []):
            if s is None:
                continue
            k = str(s).strip()
            if not k:
                continue
            key = k.lower()
            if key not in seen:
                seen.add(key)
                out.append(k)
        return out

    def _extract_keywords(*texts):
        import re
        txt = " ".join([t for t in texts if t])[:5000].lower()
        tags = re.findall(r"#([a-z0-9_]+)", txt)               # hashtag
        words = re.findall(r"[a-z0-9_]{3,}", txt)              # keyword ASCII
        return _dedup_ci_keep_order(tags + words)

    # ---------------- 3) Gom nh√≥m hashtag t·ª´ data ƒë√£ load ----------------
    # Hot (Momentum)
    hot_hashtags = []
    if 'mom_latest' in locals() and mom_latest is not None and not mom_latest.empty:
        hot_hashtags = (
            mom_latest.sort_values("view_delta", ascending=False)
            .dropna(subset=["hashtag"]).head(50)["hashtag"].astype(str).tolist()
        )

    # Evergreen (Retention)
    evergreen_hashtags = []
    if 'df_ret' in locals() and df_ret is not None and not df_ret.empty:
        evergreen_hashtags = (
            df_ret.sort_values("streak_days", ascending=False)
            .dropna(subset=["hashtag"]).head(50)["hashtag"].astype(str).tolist()
        )

    # Opportunity (view/video cao)
    opportunity_hashtags = []
    if 'df_opp' in locals() and df_opp is not None and not df_opp.empty:
        tmp = df_opp.copy()
        if all(c in tmp.columns for c in ["view_count", "video_count"]):
            tmp["vv"] = pd.to_numeric(tmp["view_count"], errors="coerce") / pd.to_numeric(tmp["video_count"], errors="coerce").replace(0, pd.NA)
            tmp = tmp.dropna(subset=["vv"]).sort_values("vv", ascending=False)
            opportunity_hashtags = tmp.head(50)["hashtag"].astype(str).tolist()

    # Proven winners (Top100)
    proven_hashtags = []
    if 'df_top100' in locals() and df_top100 is not None and not df_top100.empty:
        proven_hashtags = df_top100["hashtag"].dropna().astype(str).head(100).tolist()

    # Weekly top (best_rank t·ªët)
    weekly_hashtags = []
    if 'dfw' in locals() and dfw is not None and not dfw.empty:
        weekly_hashtags = (
            dfw.sort_values(["week", "best_rank"])
            .dropna(subset=["hashtag", "best_rank"]).head(100)["hashtag"].astype(str).tolist()
        )

    # Merge v√† kh·ª≠ tr√πng l·∫∑p (case-insensitive)
    all_suggested = _dedup_ci_keep_order(
        hot_hashtags + evergreen_hashtags + opportunity_hashtags + proven_hashtags + weekly_hashtags
    )

    # ---------------- 4) Auto-pick hashtag theo Prompt + Data ----------------
    prompt_keywords = _extract_keywords(pb_goal, pb_audience, pb_product, pb_tone, freeform_prompt)

    def _matches_prompt(tag: str) -> bool:
        t = tag.lower().lstrip("#")
        return any(kw in t for kw in prompt_keywords)

    # ∆Øu ti√™n: match prompt tr∆∞·ªõc, r·ªìi Hot/Evergreen/Opportunity/Proven/Weekly
    prefer_auto = _dedup_ci_keep_order(
        [t for t in all_suggested if _matches_prompt(t)] +
        hot_hashtags[:10] + evergreen_hashtags[:10] + opportunity_hashtags[:10] +
        proven_hashtags[:10] + weekly_hashtags[:10]
    )[:20]

    # Tr√°nh: c√°c tag ƒëang gi·∫£m (fading) + kh√¥ng li√™n quan prompt
    avoid_auto = []
    if 'mom_latest' in locals() and mom_latest is not None and not mom_latest.empty:
        fading = (
            mom_latest.sort_values("view_delta", ascending=True)
            .dropna(subset=["hashtag"]).head(30)["hashtag"].astype(str).tolist()
        )
        avoid_auto = _dedup_ci_keep_order([t for t in fading if not _matches_prompt(t)])[:20]

    st.markdown("### üè∑Ô∏è Hashtag h·ªá th·ªëng t·ª± ch·ªçn")
    st.caption("**∆Øu ti√™n** (AI s·∫Ω c·ªë g·∫Øng k·∫øt h·ª£p):")
    st.write(", ".join([f"#{h.lstrip('#')}" for h in prefer_auto]) if prefer_auto else "_(kh√¥ng c√≥)_")
    st.caption("**Tr√°nh** (AI s·∫Ω h·∫°n ch·∫ø d√πng):")
    st.write(", ".join([f"#{h.lstrip('#')}" for h in avoid_auto]) if avoid_auto else "_(kh√¥ng c√≥)_")

    # ---------------- 5) T·∫°o context t·ªïng h·ª£p (√©p ng√†y -> chu·ªói) ----------------
    trend_hot_df = pd.DataFrame()
    if 'mom_latest' in locals() and mom_latest is not None and not mom_latest.empty:
        trend_hot_df = mom_latest.sort_values("view_delta", ascending=False).head(10)[
            ["hashtag", "industry", "view_delta"]
        ].copy()

    # Ng√†nh & Qu·ªëc gia
    industry_share = pd.DataFrame()
    industry_eff = pd.DataFrame()
    country_views = pd.DataFrame()

    mx2 = run_sql_safe("SELECT MAX(DATE(dt)) AS mx FROM silver.silver_trend")
    latest2 = mx2.iloc[0]["mx"] if not mx2.empty else None
    if latest2:
        extra2 = ""
        if COUNTRIES and COUNTRIES != ["ALL"]:
            extra2 += f" AND country_code IN ({_in_list_sql([c for c in COUNTRIES if c!='ALL'])})"
        if KEYWORD:
            kw2 = str(KEYWORD).lower().replace("'", "''")
            extra2 += f" AND LOWER(COALESCE(hashtag_raw, hashtag)) LIKE '%{kw2}%'"

        industry_share = run_sql_safe(f"""
            SELECT industry, SUM(view_count) AS total_views
            FROM silver.silver_trend
            WHERE DATE(dt)=DATE('{latest2}') AND industry IS NOT NULL
            {extra2}
            GROUP BY industry
            ORDER BY total_views DESC
            LIMIT 12
        """)
        industry_eff = run_sql_safe(f"""
            SELECT 
                industry, 
                SUM(view_count) AS total_views, 
                SUM(video_count) AS total_videos,
                SUM(view_count) / NULLIF(SUM(video_count), 0) AS view_per_video
            FROM silver.silver_trend
            WHERE DATE(dt)=DATE('{latest2}') AND industry IS NOT NULL AND video_count > 0
            {extra2}
            GROUP BY industry
            ORDER BY view_per_video DESC
            LIMIT 15
        """)
        country_views = run_sql_safe(f"""
            SELECT DATE(dt) dt, country_code, SUM(view_count) AS total_views
            FROM silver.silver_trend
            {build_where(dt_col='dt', country_col='country_code', industry_col=None,
                         hashtag_expr='COALESCE(hashtag_raw, hashtag)')}
            GROUP BY 1,2
            ORDER BY 1,2
        """)
        if not country_views.empty and "dt" in country_views.columns:
            country_views["dt"] = country_views["dt"].astype(str)  # tr√°nh l·ªói JSON date

    context_payload = {
        "filters_active": {
            "start_date": str(START_DATE) if START_DATE else None,
            "end_date": str(END_DATE) if END_DATE else None,
            "countries": COUNTRIES,
            "industries": INDUSTRIES,
            "keyword": KEYWORD,
            "topn": TOPN,
        },
        "prompt_builder": {
            "goal": pb_goal or "",
            "audience": pb_audience or "",
            "product_service": pb_product or "",
            "tone": pb_tone or "",
            "kpi": pb_kpi or "",
            "constraints": pb_constraints or "",
            "freeform": freeform_prompt or "",
            "idea_count": idea_count,
            "output_language": out_lang
        },
        "hashtags": {
            "prefer": prefer_auto,
            "avoid": avoid_auto,
            "hot_top10": trend_hot_df.to_dict(orient="records") if not trend_hot_df.empty else [],
            "evergreen_top20": (
                df_ret.sort_values("streak_days", ascending=False)
                .head(20)[["hashtag", "streak_days"]].to_dict("records")
                if ('df_ret' in locals() and df_ret is not None and not df_ret.empty) else []
            ),
            "opportunity_top20": (
                pd.DataFrame({"hashtag": opportunity_hashtags[:20]}).to_dict("records")
            ),
            "proven_top100": (
                df_top100.head(100)[["hashtag", "rank", "view_count", "video_count"]].to_dict("records")
                if ('df_top100' in locals() and df_top100 is not None and not df_top100.empty) else []
            ),
            "weekly_top": weekly_hashtags[:30]
        },
        "market": {
            "industry_share_latest": industry_share.to_dict("records") if not industry_share.empty else [],
            "industry_efficiency_latest": industry_eff.to_dict("records") if not industry_eff.empty else [],
            "country_views_timeseries_head": country_views.head(50).to_dict("records") if not country_views.empty else []
        }
    }

    def _json_default(o):
        # Chuy·ªÉn m·ªçi ki·ªÉu kh√¥ng serializable sang chu·ªói an to√†n
        if isinstance(o, (_dt.date, _dt.datetime)):
            return o.isoformat()
        try:
            import numpy as _np
            if isinstance(o, (_np.integer,)):
                return int(o)
            if isinstance(o, (_np.floating,)):
                return float(o)
            if isinstance(o, (_np.ndarray,)):
                return o.tolist()
        except Exception:
            pass
        return str(o)

    system_prompt = (
        "B·∫°n l√† chi·∫øn l∆∞·ª£c gia TikTok. H√£y ƒë·ªçc k·ªπ JSON context (d·ªØ li·ªáu trend & c·∫•u h√¨nh Prompt Builder) "
        "ƒë·ªÉ ƒë·ªÅ xu·∫•t √Ω t∆∞·ªüng & k·ªãch b·∫£n c√≥ t√≠nh h√†nh ƒë·ªông cao. "
        "Lu√¥n g·ª£i √Ω hashtag k·∫øt h·ª£p gi·ªØa niche + trend, v√† n√™u r√µ v√¨ sao l·ª±a ch·ªçn ƒë√≥ ph√π h·ª£p."
    )

    builder_prompt = f"""
[Builder]
- M·ª•c ti√™u: {pb_goal or "(ch∆∞a cung c·∫•p)"}
- ƒê·ªëi t∆∞·ª£ng: {pb_audience or "(ch∆∞a cung c·∫•p)"}
- S·∫£n ph·∫©m/DV: {pb_product or "(ch∆∞a cung c·∫•p)"}
- T√¥ng gi·ªçng: {pb_tone or "(ch∆∞a cung c·∫•p)"}
- KPI: {pb_kpi or "(ch∆∞a cung c·∫•p)"}
- R√†ng bu·ªôc: {pb_constraints or "(ch∆∞a cung c·∫•p)"}
- S·ªë √Ω t∆∞·ªüng c·∫ßn t·∫°o: {idea_count}
- Ng√¥n ng·ªØ ƒë·∫ßu ra: {out_lang}
"""

    context_json_str = json.dumps(context_payload, ensure_ascii=False, default=_json_default)

    final_user_prompt = f"""
[Context JSON]
{context_json_str}

[User Prompt]
{builder_prompt}

[Y√™u c·∫ßu ƒë·∫ßu ra]
1) Ph√¢n t√≠ch k√™nh (t·ª´ g√≥c nh√¨n th·ªã tr∆∞·ªùng & Builder): n√™u niche/ƒëi·ªÉm m·∫°nh/ƒëi·ªÉm y·∫øu-c∆° h·ªôi.
2) ƒê·ªÅ xu·∫•t {idea_count} √Ω t∆∞·ªüng video. M·ªói √Ω t∆∞·ªüng b·∫Øt bu·ªôc c√≥:
   - Hook ‚â§ 3s (r·∫•t ng·∫Øn v√† m·∫°nh)
   - Visual (shot-by-shot)
   - Voiceover (ng·∫Øn, g·ªçn)
   - CTA (c·ª• th·ªÉ)
   - Hashtag ƒë·ªÅ xu·∫•t (k·∫øt h·ª£p gi·ªØa hashtag ∆∞u ti√™n v√† trend hot/evergreen ph√π h·ª£p)
3) Ch·ªçn 1 √Ω t∆∞·ªüng t·ªët nh·∫•t v√† vi·∫øt k·ªãch b·∫£n chi ti·∫øt 30‚Äì45s.
4) L·ªãch ƒëƒÉng g·ª£i √Ω 1 tu·∫ßn (gi·ªù v√†ng) + l∆∞u √Ω A/B test.
Tr√¨nh b√†y ng·∫Øn g·ªçn, r√µ r√†ng, c√≥ bullet.
"""

    with st.expander("üëÄ Xem prompt ƒë√£ t·ªïng h·ª£p (debug)"):
        st.code(final_user_prompt, language="markdown")

    st.download_button(
        "‚¨áÔ∏è T·∫£i Prompt (.txt)",
        data=final_user_prompt.encode("utf-8"),
        file_name="tiktok_prompt_compiled.txt",
        mime="text/plain"
    )
    st.download_button(
        "‚¨áÔ∏è T·∫£i Context (.json)",
        data=json.dumps(context_payload, ensure_ascii=False, indent=2, default=_json_default).encode("utf-8"),
        file_name="tiktok_context.json",
        mime="application/json"
    )

    # ---------------- 6) G·ªçi Gemini API qua requests ----------------
    run_ai = st.button("üöÄ Ph√¢n t√≠ch & G·ª£i √Ω b·∫±ng AI")
    if run_ai:
        try:
            apiKey = None
            if "gemini" in st.secrets and "api_key" in st.secrets["gemini"]:
                apiKey = st.secrets["gemini"]["api_key"]

            if not apiKey or apiKey == "YOUR_API_KEY_HERE" or len(apiKey) < 30:
                st.error("L·ªói c·∫•u h√¨nh: Kh√¥ng t√¨m th·∫•y API Key Gemini ho·∫∑c key kh√¥ng h·ª£p l·ªá.")
                st.info("Ki·ªÉm tra `.streamlit/secrets.toml`:\n\n[gemini]\napi_key = \"AIza...\"")
            else:
                MODEL_ID = "gemini-2.5-flash-preview-09-2025"
                apiUrl = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_ID}:generateContent?key={apiKey}"

                payload = {
                    "contents": [{"parts": [{"text": final_user_prompt}]}],
                    "systemInstruction": {"parts": [{"text": system_prompt}]},
                    "generationConfig": {"temperature": 0.7, "topP": 0.95}
                }
                headers = {'Content-Type': 'application/json'}

                with st.spinner("ƒêang g·ªçi AI‚Ä¶"):
                    response = requests.post(apiUrl, headers=headers, json=payload, timeout=90)

                if response.status_code == 200:
                    result = response.json()
                    text_response = "Kh√¥ng th·ªÉ l·∫•y ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ AI."
                    candidates = result.get("candidates")
                    if candidates and len(candidates) > 0:
                        content = candidates[0].get("content")
                        if content and 'parts' in content and len(content['parts']) > 0:
                            text_response = content['parts'][0].get('text', text_response)

                    st.markdown("### üì§ K·∫øt qu·∫£ t·ª´ AI")
                    st.markdown(text_response)
                else:
                    st.error(f"L·ªói khi g·ªçi AI: {response.status_code} - {response.text}")
        except Exception as e:
            st.error(f"L·ªói trong qu√° tr√¨nh g·ªçi AI: {e}")

# ===== üì£ 10. Ph√¢n t√≠ch Promote =====
# ===== üì£ 10. Ph√¢n t√≠ch Promote =====
with tabs[9]:
    st.subheader("üì£ 10. Ph√¢n t√≠ch Promote (Qu·∫£ng b√° tr·∫£ ph√≠)")
    st.markdown(
        "Ch·ª©c nƒÉng: ƒêo **t·ª∑ l·ªá hashtag ƒë∆∞·ª£c TikTok ƒë√°nh d·∫•u l√† promoted/ads** theo th·ªùi gian v√† theo qu·ªëc gia "
        "(n·∫øu c√≥), r·ªìi ƒë∆∞a ra **nh·∫≠n ƒë·ªãnh + g·ª£i √Ω chi·∫øn l∆∞·ª£c**."
    )

    df_prom = pd.DataFrame()
    prom_cols = table_columns("gold.trend_promoted_share")

    # 1) ∆Øu ti√™n d√πng b·∫£ng Gold n·∫øu c√≥ (nhanh, ƒë√£ t·ªïng h·ª£p)
    if len(prom_cols) > 0:
        has_country = "country_code" in prom_cols
        cnt_col = (
            "hashtag_cnt"
            if "hashtag_cnt" in prom_cols
            else ("total_cnt" if "total_cnt" in prom_cols else None)
        )

        where_sql = build_where(
            dt_col="dt",
            country_col="country_code" if has_country else None,
            industry_col=None,
            hashtag_expr=None,  # b·∫£ng gold kh√¥ng c√≥ hashtag => kh√¥ng l·ªçc KEYWORD
        )

        sql_prom = ""
        if cnt_col and has_country:
            # Case 1: c√≥ country_code
            sql_prom = f"""
                SELECT
                  dt,
                  country_code,
                  {cnt_col} AS hashtag_cnt,
                  promoted_cnt,
                  promoted_share
                FROM gold.trend_promoted_share
                {where_sql}
                ORDER BY dt, country_code
            """
        elif cnt_col:
            # Case 2: ch·ªâ t·ªïng to√†n h·ªá th·ªëng
            sql_prom = f"""
                SELECT
                  dt,
                  {cnt_col} AS hashtag_cnt,
                  promoted_cnt,
                  promoted_share
                FROM gold.trend_promoted_share
                {where_sql}
                ORDER BY dt
            """

        if sql_prom:
            df_prom = run_sql_safe(sql_prom)

    # 2) Fallback: t√≠nh tr·ª±c ti·∫øp t·ª´ Silver n·∫øu Gold kh√¥ng c√≥ / r·ªóng
    if df_prom.empty:
        sql_prom_fb = f"""
        SELECT
          DATE(dt) AS dt,
          country_code,
          COUNT(*) AS hashtag_cnt,
          SUM(CASE WHEN is_promoted THEN 1 ELSE 0 END) AS promoted_cnt,
          SUM(CASE WHEN is_promoted THEN 1 ELSE 0 END) / NULLIF(COUNT(*),0) AS promoted_share
        FROM silver.silver_trend
        {build_where(dt_col='dt', country_col='country_code', industry_col=None,
                     hashtag_expr='COALESCE(hashtag_raw, hashtag)')}
        GROUP BY DATE(dt), country_code
        ORDER BY dt, country_code
        """
        df_prom = run_sql_safe(sql_prom_fb)

    df_prom = dedup_cols(df_prom)
    df_prom = uniquify_columns(df_prom)

    if df_prom.empty:
        st.info(
            "Kh√¥ng c√≥ d·ªØ li·ªáu Promote (ch∆∞a c√≥ c·ªôt `is_promoted` ho·∫∑c ch∆∞a c√≥ hashtag n√†o ƒë∆∞·ª£c ƒë√°nh d·∫•u)."
        )
    else:
        # Chu·∫©n ho√° ki·ªÉu d·ªØ li·ªáu
        for col in ["hashtag_cnt", "promoted_cnt", "promoted_share"]:
            if col in df_prom.columns:
                df_prom[col] = pd.to_numeric(df_prom[col], errors="coerce")

        if "promoted_share" not in df_prom.columns and all(
            c in df_prom.columns for c in ["promoted_cnt", "hashtag_cnt"]
        ):
            df_prom["promoted_share"] = df_prom["promoted_cnt"] / df_prom["hashtag_cnt"].replace(0, pd.NA)

        df_prom["promoted_share_pct"] = df_prom["promoted_share"] * 100

        # Chu·∫©n ho√° dt
        if "dt" in df_prom.columns:
            df_prom["dt"] = pd.to_datetime(df_prom["dt"])

        # 3) KPI: to√†n b·ªô & 7 ng√†y g·∫ßn nh·∫•t
        total_hashtags = df_prom["hashtag_cnt"].sum() if "hashtag_cnt" in df_prom.columns else None
        total_promoted = df_prom["promoted_cnt"].sum() if "promoted_cnt" in df_prom.columns else None
        global_share = None
        if (
            total_hashtags is not None
            and total_promoted is not None
            and total_hashtags > 0
        ):
            global_share = total_promoted / total_hashtags

        latest_dt = df_prom["dt"].max() if "dt" in df_prom.columns else None
        from datetime import timedelta

        last7_share = None
        df_last7 = pd.DataFrame()
        if latest_dt is not None:
            last7_start = latest_dt - timedelta(days=6)
            df_last7 = df_prom[(df_prom["dt"] >= last7_start) & (df_prom["dt"] <= latest_dt)]
            if not df_last7.empty and "hashtag_cnt" in df_last7.columns:
                total7 = df_last7["hashtag_cnt"].sum()
                prom7 = df_last7["promoted_cnt"].sum() if "promoted_cnt" in df_last7.columns else None
                if prom7 is not None and total7 > 0:
                    last7_share = prom7 / total7

        def classify_paid_level(x):
            import pandas as _pd
            if x is None or _pd.isna(x):
                return "Kh√¥ng r√µ"
            if x < 0.02:
                return "‚ú® Ch·ªß y·∫øu Organic"
            if x < 0.10:
                return "‚öñÔ∏è Organic + Paid c√¢n b·∫±ng"
            return "üî• Ads-heavy (Promote nhi·ªÅu)"

        col1p, col2p, col3p = st.columns(3)
        col1p.metric(
            "T·ª∑ l·ªá promoted (to√†n b·ªô giai ƒëo·∫°n)",
            f"{global_share*100:.1f}%" if global_share is not None else "N/A",
        )
        col2p.metric(
            "T·ª∑ l·ªá promoted 7 ng√†y g·∫ßn nh·∫•t",
            f"{last7_share*100:.1f}%" if last7_share is not None else "N/A",
        )
        col3p.metric(
            "Nh·∫≠n ƒë·ªãnh th·ªã tr∆∞·ªùng",
            classify_paid_level(last7_share if last7_share is not None else global_share),
        )

        # 4) Bi·ªÉu ƒë·ªì theo th·ªùi gian
        st.markdown("#### ‚è±Ô∏è T·ª∑ l·ªá hashtag promoted theo th·ªùi gian")
        if px is not None and "dt" in df_prom.columns:
            if "country_code" in df_prom.columns:
                fig_ps = px.line(
                    df_prom,
                    x="dt",
                    y="promoted_share_pct",
                    color="country_code",
                    title="% hashtag promoted (theo qu·ªëc gia)",
                    labels={
                        "promoted_share_pct": "% hashtag c√≥ flag promoted",
                        "country_code": "Qu·ªëc gia",
                    },
                )
            else:
                fig_ps = px.line(
                    df_prom,
                    x="dt",
                    y="promoted_share_pct",
                    title="% hashtag promoted (to√†n h·ªá th·ªëng)",
                    labels={"promoted_share_pct": "% hashtag c√≥ flag promoted"},
                )
            fig_ps.update_yaxes(ticksuffix="%")
            plot_stretch(fig_ps)

        # 5) Snapshot theo ng√†y m·ªõi nh·∫•t (n·∫øu c√≥ country_code)
        if "country_code" in df_prom.columns and latest_dt is not None and px is not None:
            st.markdown("#### üìç Snapshot theo ng√†y m·ªõi nh·∫•t theo qu·ªëc gia")
            latest_df = df_prom[df_prom["dt"] == latest_dt].copy()
            latest_df = latest_df.sort_values("promoted_share_pct", ascending=False)
            if not latest_df.empty:
                fig_latest = px.bar(
                    latest_df,
                    x="promoted_share_pct",
                    y="country_code",
                    orientation="h",
                    title=f"T·ª∑ l·ªá hashtag promoted theo qu·ªëc gia ‚Äî {latest_dt.date()}",
                    labels={
                        "promoted_share_pct": "% hashtag promoted",
                        "country_code": "Qu·ªëc gia",
                    },
                    hover_data=(
                        ["hashtag_cnt", "promoted_cnt"]
                        if "hashtag_cnt" in latest_df.columns
                        else None
                    ),
                )
                fig_latest.update_xaxes(ticksuffix="%")
                fig_latest.update_yaxes(autorange="reversed")
                plot_stretch(fig_latest)

        # 6) G·ª£i √Ω chi·∫øn l∆∞·ª£c (t·ª± ƒë·ªông)
        st.markdown("#### üß† G·ª£i √Ω chi·∫øn l∆∞·ª£c (t·ª± ƒë·ªông)")
        if global_share is None or (
            global_share == 0 and (last7_share is None or last7_share == 0)
        ):
            st.write(
                "- D·ªØ li·ªáu hi·ªán t·∫°i h·∫ßu nh∆∞ **kh√¥ng c√≥ hashtag Promote** ‚Üí th·ªã tr∆∞·ªùng ƒëang ch·ªß y·∫øu organic.\n"
                "- H√£y xem ƒë√¢y l√† **baseline**: sau n√†y khi ch·∫°y Promote, ƒë∆∞·ªùng bi·ªÉu ƒë·ªì s·∫Ω nh·∫£y l√™n ƒë·ªÉ so s√°nh tr∆∞·ªõc/sau chi·∫øn d·ªãch.\n"
                "- G·ª£i √Ω: t·∫≠p trung t·ªëi ∆∞u **n·ªôi dung & hashtag organic** ·ªü c√°c tab 1‚Äì8 tr∆∞·ªõc, r·ªìi quay l·∫°i tab n√†y ƒë·ªÉ ƒëo hi·ªáu qu·∫£ qu·∫£ng c√°o."
            )
        else:
            lines = []
            if last7_share is not None and global_share is not None:
                diff = last7_share - global_share
                if abs(diff) < 0.005:
                    lines.append(
                        f"- T·ª∑ l·ªá Promote 7 ng√†y g·∫ßn ƒë√¢y **·ªïn ƒë·ªãnh** quanh m·ª©c trung b√¨nh ({global_share*100:.1f}%)."
                    )
                elif diff > 0:
                    lines.append(
                        f"- T·ª∑ l·ªá Promote 7 ng√†y g·∫ßn ƒë√¢y **tƒÉng** so v·ªõi trung b√¨nh (‚Üë {diff*100:.1f} ƒëi·ªÉm ph·∫ßn trƒÉm)."
                    )
                else:
                    lines.append(
                        f"- T·ª∑ l·ªá Promote 7 ng√†y g·∫ßn ƒë√¢y **gi·∫£m** so v·ªõi trung b√¨nh (‚Üì {abs(diff)*100:.1f} ƒëi·ªÉm ph·∫ßn trƒÉm)."
                    )

            if "country_code" in df_prom.columns:
                country_agg = (
                    df_prom.groupby("country_code", as_index=False)
                    .agg(
                        total_hashtag=("hashtag_cnt", "sum"),
                        total_promoted=("promoted_cnt", "sum"),
                    )
                )
                country_agg["share"] = country_agg["total_promoted"] / country_agg[
                    "total_hashtag"
                ].replace(0, pd.NA)
                country_agg = country_agg.dropna(subset=["share"]).sort_values(
                    "share", ascending=False
                )
                if not country_agg.empty:
                    top_row = country_agg.iloc[0]
                    lines.append(
                        f"- Qu·ªëc gia c√≥ t·ª∑ l·ªá Promote cao nh·∫•t to√†n giai ƒëo·∫°n: **{top_row['country_code']} ‚Äî {top_row['share']*100:.1f}%**."
                    )

            lines.append(
                "- N·∫øu t·ª∑ l·ªá Promote cao ‚Üí n√™n t·∫≠p trung ng√¢n s√°ch v√†o c√°c hashtag **ƒë√£ ch·ª©ng minh hi·ªáu qu·∫£** (tab 7) "
                "v√† c√≥ **Momentum t·ªët** (tab 2)."
            )
            lines.append(
                "- N·∫øu t·ª∑ l·ªá Promote th·∫•p nh∆∞ng b·∫°n mu·ªën push nhanh ‚Üí ch·ªçn c√°c hashtag **c∆° h·ªôi** (tab 1) "
                "ƒë·ªÉ ch·∫°y Promote, v√¨ c·∫°nh tranh c√≤n th·∫•p."
            )
            st.write("\n".join(lines))

        show_data_expander(df_prom, "Xem d·ªØ li·ªáu Promote chi ti·∫øt")
        csv_download(df_prom, "promoted_share_by_country.csv")


# ---- G·ª£i √Ω c√†i plotly n·∫øu thi·∫øu ----
if px is None:
    st.warning("Plotly ch∆∞a ƒë∆∞·ª£c c√†i. Ch·∫°y: pip install plotly==5.24.1 ƒë·ªÉ xem bi·ªÉu ƒë·ªì.")
